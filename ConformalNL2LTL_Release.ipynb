{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQhMZ8HQlOVA"
      },
      "source": [
        "# **ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees**\n",
        "\n",
        "***Jun Wang<sup>1&#42;</sup>, David Smith Sundarsingh<sup>1&#42;</sup>, Jyotirmoy V. Deshmukh, Yiannis Kantaros<sup>1</sup>***\n",
        "\n",
        "*Department of Electrical and Systems Engineering, Washington University in St Louis<sup>1</sup>*\n",
        "\n",
        "*Department of Computer Science, University of Southern California<sup>2</sup>*\n",
        "\n",
        "&#42; indicates equal contribution.\n",
        "\n",
        "\n",
        "Copyright 2025 [Kantaros Lab @ WashU](https://sites.wustl.edu/kantaroslab/). All rights reserved.\n",
        "\n",
        "Please check project webpage [conformalnl2ltl.github.io](https://conformalnl2ltl.github.io/) for more information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDS7Odxdfjpb"
      },
      "outputs": [],
      "source": [
        "API_KEY_PRI = \"OpenAI API key of your primary model\"\n",
        "API_KEY_SEC = \"OpenAI API key of your secondary model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRdXxfQBX32s"
      },
      "source": [
        "## LLM Configurations\n",
        "\n",
        "***Google drive access will be requested to save data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8TaEoJ88_pd",
        "outputId": "7231c27b-8309-4dad-a26e-a90ee302c303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/389.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m389.1/389.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.5/389.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.55.2 httpx==0.27.2 --quiet\n",
        "import ollama\n",
        "import json\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "from openai import OpenAI\n",
        "import os:\n",
        "    os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IVuBASTX9lpw"
      },
      "outputs": [],
      "source": [
        "#@title API Call Function\n",
        "client = OpenAI(api_key=API_KEY_PRI, base_url=\"https://api.deepseek.com\")\n",
        "client_gpt = OpenAI(api_key=API_KEY_PRI)\n",
        "def LLM_DS(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"deepseek-chat\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        stream=False\n",
        "    )\n",
        "    text = response.choices[0].message.content\n",
        "    index = text.find('\\n')\n",
        "    first_line = text[:index] if index != -1 else text\n",
        "\n",
        "    return response, first_line\n",
        "\n",
        "def GPT(messages):\n",
        "    response = client_gpt.chat.completions.create(\n",
        "        model='gpt-4o',\n",
        "        messages=messages,\n",
        "        temperature=1,\n",
        "        max_tokens=512,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        response_format={\"type\": \"text\"}\n",
        "    )\n",
        "    return response, response.choices[0].message.content\n",
        "\n",
        "def formulator(role, text):\n",
        "    message = {\n",
        "    \"role\": role,\n",
        "    \"content\": [{\n",
        "            \"text\": text,\n",
        "            \"type\": \"text\"\n",
        "    }]}\n",
        "    return message\n",
        "\n",
        "def LLM(prompt, model, tokenizer):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=50,\n",
        "        do_sample=True,\n",
        "        top_p=1,\n",
        "        temperature=1\n",
        "    )\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(decoded)\n",
        "\n",
        "    # Split at <start_of_turn>model and take the last part\n",
        "    lines = decoded.splitlines()\n",
        "\n",
        "    response = None\n",
        "    found_model = False\n",
        "\n",
        "    for line in lines:\n",
        "        if found_model:\n",
        "            if line.strip():         # first non-empty line after \"model\"\n",
        "                response = line.strip()\n",
        "                break\n",
        "        elif line.strip() == \"model\":\n",
        "            found_model = True\n",
        "\n",
        "    if response is None or \"model\" in response:\n",
        "        print(f\"Nod model output found.\")\n",
        "        return \"\"\n",
        "    else:\n",
        "        print(f\"The output is: {response}\")\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XInySBUh-RXU"
      },
      "outputs": [],
      "source": [
        "#@title Semantic similarity computation\n",
        "def extract_text_and_number(text):\n",
        "    # Extract the number\n",
        "    number_match = re.search(r'\\d+', text)\n",
        "    number = int(number_match.group()) if number_match else None\n",
        "    # Extract the non-numeric part\n",
        "    text_part = re.sub(r'\\d+', '', text).strip('_')\n",
        "    text_part = text_part.replace('_', ' ')\n",
        "    return text_part, number\n",
        "\n",
        "# text-embedding-ada-002, text-embedding-3-large, text-embedding-3-small\n",
        "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
        "    response = ollama.embeddings(model='nomic-embed-text', prompt=text)\n",
        "    return response['embedding']\n",
        "\n",
        "def cos(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "def semantic_similarity(text1, text2):\n",
        "    w1, n1 = extract_text_and_number(text1)\n",
        "    w2, n2 = extract_text_and_number(text2)\n",
        "    vector1 = np.array(get_embedding(w1))\n",
        "    vector2 = np.array(get_embedding(w2))\n",
        "    if n1 != n2:\n",
        "      # stop considering semantic similarity if the numbers do not match\n",
        "      return 0\n",
        "    cos_sim = cos(vector1, vector2)\n",
        "    similarity = cos_sim\n",
        "    return similarity\n",
        "\n",
        "print(semantic_similarity('stay_hall_2', 'hall_2e'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VpQboUAN-uJ4"
      },
      "outputs": [],
      "source": [
        "def check_validity(new_string):\n",
        "  pattern = r'(?<!\\w)(<>|!|->|&&|\\|\\||\\[\\]|U|\\(|\\)|/|[a-zA-Z0-9_]+)(?!\\w)'\n",
        "  found_keys = re.findall(pattern, new_string)\n",
        "  if len(found_keys) == 1:\n",
        "    return True, found_keys\n",
        "  elif len(found_keys) > 1:\n",
        "        return False, found_keys  # Invalid string with the conflicting keys\n",
        "  else:\n",
        "    return False, []\n",
        "  \n",
        "class CustomOutput:\n",
        "    def __init__(self, file):\n",
        "        self.file = file\n",
        "\n",
        "    def write(self, message):\n",
        "        print(message, end='')  # Print to console\n",
        "        self.file.write(message)  # Write to file\n",
        "\n",
        "    def flush(self):\n",
        "        pass  # For compatibility with `print`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zoI1PJvhimC"
      },
      "source": [
        "## System Prompt\n",
        "\n",
        "The translation of Natural Language (NL) task into Linear Temporal Logic (LTL) formula is constructed incrementally as a sequence of interdependent multiple-choice-question-answering (MCQA) tasks.\n",
        "\n",
        "At each time step, we query the LLM $m$ times to generate $m$ candidate response, each response can be either\n",
        "*   An operator comes from a fixed pre-defined set\n",
        "*   An atomic proposition that is generated based on the rules defined in the prompt\n",
        "\n",
        "Operators we considered:\n",
        "\n",
        "|     Symbol    |  Explanation  |\n",
        "|:-------------:|:-------------:|\n",
        "|      $<>$     |   Eventually  |\n",
        "|      $!$      |    Negation   |\n",
        "| $\\rightarrow$ |  Implication  |\n",
        "|     $\\&\\&$    |      And      |\n",
        "|     $||$    |       OR      |\n",
        "|      $[]$     |     Always    |\n",
        "|      $U$      |     Until     |\n",
        "|      $($      |  Left Bracket |\n",
        "|      $)$      | Right Bracket |\n",
        "|      $/$      | Ending Symbol |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Dq4LZQxK91V9"
      },
      "outputs": [],
      "source": [
        "#@title List of Temporal/Logical Operators\n",
        "operators = {\n",
        "    '<>': 'eventually',\n",
        "    '!' : 'negation',\n",
        "    '->': 'implication',\n",
        "    '&&': 'and',\n",
        "    '||': 'or',\n",
        "    '[]': 'always',\n",
        "    'U' : 'until',\n",
        "    '(' : 'left bracket',\n",
        "    ')' : 'right bracket',\n",
        "    '/': 'only upon LTL formula completion.'\n",
        "}\n",
        "\n",
        "opkeys = list(operators.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cbo5doxUwLQG"
      },
      "outputs": [],
      "source": [
        "#@title Prompt for the primary model\n",
        "formatted_operators = '\\n'.join([ops[0] + ' # ' + ops[1] for ops in operators.items()])\n",
        "gpt_system_prompt = f\"\"\"You are a helpful assistant tasked with translating natural language (NL) instructions into Linear Temporal Logic (LTL) formulas step by step.\n",
        "\n",
        "At each step, generate exactly 1 element either an operator strictly from the set of Logical and Temporal Operators listed below or an Atomic Predicates by following the construction rules below.\n",
        "\n",
        "Possible Options:\n",
        "For temporal and logical operators, you must pick only one from the below elements and nothing else:\n",
        "<> # eventually\n",
        "! # negation\n",
        "-> # implication\n",
        "&& # and\n",
        "|| # or\n",
        "[] # always\n",
        "U # until\n",
        "( # left bracket\n",
        ") # right bracket\n",
        "/ # only upon LTL formula completed\n",
        "\n",
        "Atomic Predicates construction rules (AP):\n",
        "The robot can a) go to a location; b) pick up an item; c) put down an item; and d) take a photo.\n",
        "At each step, if you need to generate an atomic predicate for one of the capabilities, you must follow the rules below:\n",
        "Go to [location X] is written as location_X\n",
        "Pick up [item X] is written as p_item_X\n",
        "Put down is written as pd\n",
        "take a photo is written as photo\n",
        "\n",
        "!! You can only select one operator or one AP at a given step !!\n",
        "\n",
        "Do not generate \"<>(\" at the same step but generate \"<>\" first and then \"(\".\n",
        "\n",
        "Example NL Instruction: Deliver package 4 to store 5 after picking it up from warehouse 1 as you keep visiting charger 4.\n",
        "Process Example:\n",
        "[User]:\n",
        "Formula so far:\n",
        "Step 1:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>\n",
        "Step 2:\n",
        "[Assistant]:\n",
        "(\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(\n",
        "Step 3:\n",
        "[Assistant]:\n",
        "warehouse_4\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1\n",
        "Step 4:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&\n",
        "Step 5:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>\n",
        "Step 6:\n",
        "[Assistant]:\n",
        "(\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(\n",
        "Step 7:\n",
        "[Assistant]:\n",
        "p_package_4\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4\n",
        "Step 8:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&\n",
        "Step 9:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>\n",
        "Step 10:\n",
        "[Assistant]:\n",
        "(\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(\n",
        "Step 11:\n",
        "[Assistant]:\n",
        "store_5\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5\n",
        "Step 12:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5&&\n",
        "Step 13:\n",
        "[Assistant]:\n",
        "pd\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd\n",
        "Step 14:\n",
        "[Assistant]:\n",
        ")\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd)\n",
        "Step 15:\n",
        "[Assistant]:\n",
        ")\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd))\n",
        "Step 16:\n",
        "[Assistant]:\n",
        ")\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd)))\n",
        "Step 17:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far:<>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd)))&&\n",
        "Step 18:\n",
        "[Assistant]:\n",
        "[]\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd)))&&[]\n",
        "Step 19:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd)))&&[]<>\n",
        "Step 20:\n",
        "[Assistant]:\n",
        "charger_4\n",
        "\n",
        "[User]:\n",
        "Formula so far: <>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd)))&&[]<>charger_4\n",
        "Step 21:\n",
        "[Assistant]:\n",
        "/\n",
        "\n",
        "Final LTL formula:\n",
        "<>(warehouse_1&&<>(p_package_4&&<>(store_5&&pd)))&&[]<>charger_4/\n",
        "\n",
        "Some other examples of NL instructions and their corresponding LTL formulas:\n",
        "\n",
        "NL Instruction: Take block 3 from house 3 to house 4.\n",
        "Final LTL formula:\n",
        "<>(house_3&&<>(p_block_3&&<>(house_4&&pd)))/\n",
        "\n",
        "NL Instruction: Keep taking a picture of house 6.\n",
        "\n",
        "Process Example:\n",
        "[User]:\n",
        "Formula so far:\n",
        "Step 1:\n",
        "[Assistant]:\n",
        "[]\n",
        "\n",
        "[User]:\n",
        "Formula so far: []\n",
        "Step 2:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: []<>\n",
        "Step 3:\n",
        "[Assistant]:\n",
        "(\n",
        "\n",
        "[User]:\n",
        "Formula so far: []<>(\n",
        "Step 4:\n",
        "[Assistant]:\n",
        "house_6\n",
        "\n",
        "[User]:\n",
        "Formula so far: []<>(house_6\n",
        "Step 5:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: []<>(house_6&&\n",
        "Step 6:\n",
        "[Assistant]:\n",
        "photo\n",
        "\n",
        "[User]:\n",
        "Formula so far: []<>(house_6&&photo\n",
        "Step 7:\n",
        "[Assistant]:\n",
        ")\n",
        "\n",
        "[User]:\n",
        "Formula so far: []<>(house_6&&photo)\n",
        "Step 8:\n",
        "[Assistant]:\n",
        "/\n",
        "\n",
        "Final LTL formula:\n",
        "[]<>(house_6&&photo)/\n",
        "\n",
        "NL Instruction: Stay in interstate 64 until you reach gas station 4 as you take box 1 from house 5 to then house 6.\n",
        "\n",
        "Process Example:\n",
        "[User]:\n",
        "Formula so far:\n",
        "Step 1:\n",
        "[Assistant]:\n",
        "insterstate_64\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64\n",
        "Step 2:\n",
        "[Assistant]:\n",
        "U\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64U\n",
        "Step 3:\n",
        "[Assistant]:\n",
        "gas_station_4\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4\n",
        "Step 4:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&\n",
        "Step 5:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>\n",
        "Step 6:\n",
        "[Assistant]:\n",
        "(\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(\n",
        "Step 7:\n",
        "[Assistant]:\n",
        "house_5\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5\n",
        "Step 8:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&\n",
        "Step 9:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>\n",
        "Step 10:\n",
        "[Assistant]:\n",
        "(\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(\n",
        "Step 11:\n",
        "[Assistant]:\n",
        "p_box_1\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1\n",
        "Step 12:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&\n",
        "Step 13:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>\n",
        "Step 14:\n",
        "[Assistant]:\n",
        "(\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>(\n",
        "Step 15:\n",
        "[Assistant]:\n",
        "house_6\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>(house_6\n",
        "Step 16:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>(house_6&&\n",
        "Step 17:\n",
        "[Assistant]:\n",
        "pd\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>(house_6&&pd\n",
        "Step 18:\n",
        "[Assistant]:\n",
        ")\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>(house_6&&pd)\n",
        "Step 19:\n",
        "[Assistant]:\n",
        ")\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>(house_6&&pd))\n",
        "Step 20:\n",
        "[Assistant]:\n",
        ")\n",
        "\n",
        "[User]:\n",
        "Formula so far: insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>(house_6&&pd)))\n",
        "Step 21:\n",
        "[Assistant]:\n",
        "/\n",
        "\n",
        "Final LTL formula:\n",
        "insterstate_64Ugas_station_4&&<>(house_5&&<>(p_box_1&&<>(house_6&&pd)))/\n",
        "\n",
        "NL Instruction: Do not enter lot 3 until you reach building 2 while going to building 2 and taking a picture.\n",
        "Final LTL formula:\n",
        "!lot_3Ubuilding_2&&<>(building_2&&photo)/\n",
        "\n",
        "NL Instruction: While never going to street 5, take a picture of mall 4.\n",
        "\n",
        "Process Example:\n",
        "[User]:\n",
        "Formula so far:\n",
        "Step 1:\n",
        "[Assistant]:\n",
        "[]\n",
        "\n",
        "[User]:\n",
        "Formula so far: []\n",
        "Step 2:\n",
        "[Assistant]:\n",
        "!\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!\n",
        "Step 3:\n",
        "[Assistant]:\n",
        "street_5\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!street_5\n",
        "Step 4:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!street_5&&\n",
        "Step 5:\n",
        "[Assistant]:\n",
        "<>\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!street_5&&<>\n",
        "Step 6:\n",
        "[Assistant]:\n",
        "(\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!street_5&&<>(\n",
        "Step 7:\n",
        "[Assistant]:\n",
        "mall_4\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!street_5&&<>(mall_4\n",
        "Step 8:\n",
        "[Assistant]:\n",
        "&&\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!street_5&&<>(mall_4&&\n",
        "Step 9:\n",
        "[Assistant]:\n",
        "photo\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!street_5&&<>(mall_4&&photo\n",
        "Step 10:\n",
        "[Assistant]:\n",
        ")\n",
        "\n",
        "[User]:\n",
        "Formula so far: []!street_5&&<>(mall_4&&photo)\n",
        "Step 11:\n",
        "[Assistant]:\n",
        "/\n",
        "\n",
        "Final LTL formula:\n",
        "[]!street_5&&<>(mall_4&&photo)/\n",
        "\n",
        "NL Instruction: Go to street 3 and stay there, but do not go there till you reach intersection 4\n",
        "Final LTL formula:\n",
        "<>[]street_3&&!street_3Uintersection_4/\n",
        "\n",
        "NL Instruction: Take a picture of statue 2 and then go to bench 5\n",
        "Final LTL formula:\n",
        "<>(statue_2&&photo&&<>bench_5)/\n",
        "\n",
        "NL Instruction: Stay in statue 2 as you go to bench 5\n",
        "Final LTL formula:\n",
        "[]statue_2&&<>bench_5/\n",
        "\n",
        "NL Instruction: Stay in area 4 until you take letter 2 from office 4 to office 8\n",
        "Final LTL formula:\n",
        "area_4U(office_4&&<>(p_letter_2&&<>(office_8&&pd)))/\n",
        "\n",
        "Task Instructions You Must Follow:\n",
        "1. For the given NL instruction, build the LTL formula step by step.\n",
        "2. When you are asked to select an element:\n",
        "2a. You must only choose exactly one element, either a single operator listed or an AP generated, that will build up the LTL formula to satisfy the NL description\n",
        "2b. '[]' and '!' are to be considered separate elements and should not be generated together.\n",
        "2c. '<>' and '(' are to be considered separate elements and should not be generated together.\n",
        "2d. '!' and '(' are to be considered separate elements and should not be generated together.\n",
        "2e. Do not generate part of the element\n",
        "2f. The operator 'U' is not preceeded or succeeded by operators\n",
        "3. When you generate AP as an option, make sure the name of the location or item in your response has the same semantic meaning as described in the NL instruction.\n",
        "4. Whenever you generate a left bracket \"(\", you must generate a corresponding right bracket \")\" later in the formula so that all the brackets are complete and maintain proper precedence.\n",
        "5. If the NL task indicates that the AP generated is the first of a sequence, the AP must be preceeded by '('.\n",
        "\"\"\"\n",
        "\n",
        "print(system_description_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn2YEVM1gXta"
      },
      "source": [
        "## Calibration\n",
        "\n",
        "We generated a dataset of 1,000 task-formula pairs that are of three levels of complexity.\n",
        "\n",
        "|        | # of Atomic Propositions | Dataset Size |\n",
        "|:------:|:------------------------:|:------------:|\n",
        "|  Easy  |          {1, 2}          |      365     |\n",
        "| Medium |          {3, 4}          |      440     |\n",
        "| Hard   |        More than 4       |      195     |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhvXLqrC5rg"
      },
      "source": [
        "### Load the Calibration and Validation Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Select Coverage Level\n",
        "coverage_in_percentage = 95 # @param {type:\"number\"}\n",
        "alpha = 1-coverage_in_percentage/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nxo8csuJLj1",
        "outputId": "5f5fb10c-4be8-4e78-a383-6a45e9249a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "\n",
            "JSON file loaded successfully!\n",
            "\n",
            "Length of Dataset: 1000\n",
            "\n",
            "Example Data: {'nlTask': 'Take a picture of building 2', 'ltlequ': '<>(building_2&&photo)/'}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random \n",
        "\n",
        "\n",
        "\n",
        "valid_root_path = f'Input the path where the results have to be stored'\n",
        "if not os.path.exists(valid_root_path):\n",
        "    os.makedirs(valid_root_path)\n",
        "\n",
        "group_index = str(f'Validation_{len(os.listdir(valid_root_path))+1}')\n",
        "valid_path = os.path.join(valid_root_path, str(group_index))\n",
        "if not os.path.exists(valid_path):\n",
        "    os.makedirs(valid_path)\n",
        "\n",
        "\n",
        "total_sample = 220\n",
        "calib_count = 200\n",
        "\n",
        "# obtain the quantile for both models\n",
        "ensemble_score = \"/Dataset/max_scores.json\"\n",
        "with open(ensemble_score, 'r') as score_file:\n",
        "   ensemblescores = json.load(score_file)\n",
        "n = len(ensemblescores)\n",
        "calib_idxs = random.sample(range(n), calib_count)\n",
        "compute = []\n",
        "for i in calib_idxs:\n",
        "   compute.append(int(ensemblescores[i]['score']))\n",
        "for score in ensemblescores:\n",
        "   compute.append(score['score'])\n",
        "quantile_ensemble = np.quantile(compute, 1 - alpha)\n",
        "\n",
        "print(f\"The scores are {compute}\")\n",
        "\n",
        "test_json_record = []\n",
        "test_nl_tasks = []\n",
        "for i in test_idxs:\n",
        "   test_nl_tasks.append(scores[i]['nltask'])\n",
        "ds_dataset = 'final_calib.json'\n",
        "with open(ds_dataset, 'r') as dataset_file:\n",
        "    total_dataset = json.load(dataset_file)\n",
        "task_map = {item[\"nlTask\"]: item[\"ltlequ\"] for item in total_dataset}\n",
        "# test_data =  {k: task_map[k] for k in test_nl_tasks if k in task_map}\n",
        "test_data  = {}\n",
        "for k in test_nl_tasks:\n",
        "    if k in task_map:\n",
        "      test_data[k] = task_map[k]\n",
        "\n",
        "print(f\"Now setting up validation group {group_index}\\nData will be saved at: {valid_path}\")\n",
        "print(f\"Calibration Size: {calib_count} | Validation Size: {total_sample-calib_count}\")\n",
        "print(f\"Ensemble quantile for {coverage_in_percentage}% coverage: {quantile_ensemble}\")\n",
        "  \n",
        "\n",
        "with open(os.path.join(valid_path, 'test_data.json'), 'w') as f:\n",
        "    json.dump(test_data, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjT7rtPnj9mD"
      },
      "source": [
        "## Validation with Help\n",
        "\n",
        "After you obtain the calibration dataset, we can now sample a subset from it to compute the quantile based on custom $1-\\alpha$ coverage level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbRlsS3e7qw4"
      },
      "outputs": [],
      "source": [
        "def CallCPT(api_call_per_step, messages, quantile_gpt, deepseek_predset, mywriter):\n",
        "    results = {}\n",
        "    gpt_response = []\n",
        "    for t in range(1, api_call_per_step+1):\n",
        "        mywriter.write(f\"\\nGPT Running in Progress: {t}/{api_call_per_step}\")\n",
        "        response, response_text = GPT(messages)\n",
        "        valid, found_keys = check_validity(response_text)\n",
        "        gpt_response.append({'is_valid': valid, 'text': response_text, 'found_keys': found_keys})\n",
        "        mywriter.write(f\"\\n-------[GPT][Valid: {valid}]---------\\n\" + f\"LLM Response {t}: \" + response_text.replace('\\n', '') + f\"\\nKeys Found: {found_keys}\")\n",
        "        if valid:\n",
        "            if found_keys[0] not in results:\n",
        "                results[found_keys[0]] = 0\n",
        "            results[found_keys[0]] += 1\n",
        "        if len(found_keys) == 0:\n",
        "            continue\n",
        "        print(f\"\\nAdded to {found_keys[0]}\")\n",
        "    print(f\"The results vector is {results}\")\n",
        "    total = sum(results.values())\n",
        "    valid_results = {key: value / total for key, value in results.items()}\n",
        "\n",
        "    for k, v in valid_results.items():\n",
        "      print(f\"{k}: {v}\\n\")\n",
        "    \n",
        "    # List to keep track of keys to remove\n",
        "    keys_to_remove = []\n",
        "    for key1, key2 in combinations(results.keys(), 2):\n",
        "      if semantic_similarity(key1, key2) > 0.7:\n",
        "        print(f\"High similarity {semantic_similarity(key1, key2)} between '{key1}' and '{key2}'\")\n",
        "        if valid_results[key1] >= valid_results[key2]:\n",
        "            valid_results[key1] += valid_results[key2]\n",
        "            keys_to_remove.add(key2)\n",
        "        else:\n",
        "            valid_results[key2] += valid_results[key1]\n",
        "            keys_to_remove.add(key1)\n",
        "\n",
        "    # Remove marked keys from the dictionary\n",
        "    for key in keys_to_remove:\n",
        "        if key in valid_results:\n",
        "            del valid_results[key]\n",
        "    \n",
        "    pred_set = []\n",
        "    for k, v in valid_results.items():\n",
        "      if v >= 1-quantile_gpt:\n",
        "        pred_set.append(k)\n",
        "\n",
        "    intersection = list(set(pred_set) & set(deepseek_predset))\n",
        "    mywriter.write(f\"\\n===\\nDeepSeek Pred Set: {deepseek_predset}\\nGPT Pred Set: {pred_set}\\nIntersection Prediction Set of DeepSeek and GPT is: {intersection}\\n===\\n\")\n",
        "    return intersection, pred_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6GsqRdPGXTm"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(valid_path, 'test_data.json'), \"r\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "alpha = 0.01\n",
        "opkeys = operators.keys()\n",
        "api_per_step = 10\n",
        "gpt_api_call_per_step = 10\n",
        "\n",
        "for i, (natural_language_task, ltlequ) in enumerate(test_data.items()):\n",
        "    ltlequ = ltlequ[0]\n",
        "    print(natural_language_task, ltlequ)\n",
        "    words = re.findall(r'[a-zA-TV-Z_0-9]+|<>|&&|\\|\\||\\[\\]|\\(|\\)|U|[^\\s\\w]', ltlequ)\n",
        "    \n",
        "    \n",
        "    foldername = os.path.join(valid_path, str(f\"Valid_{i+1}\"))\n",
        "    if not os.path.exists(foldername):\n",
        "        os.makedirs(foldername)\n",
        "\n",
        "    data = []\n",
        "    data_loc = os.path.join(foldername, 'data.npy')\n",
        "    print(f\"Data will be saved in {data_loc}\")\n",
        "\n",
        "    scores = []\n",
        "    text_name = \"system_description\"\n",
        "    text_path = f'/Users/davidsmithsundarsingh/Language Models/ConformalNL2LTL/{text_name}.txt'\n",
        "    with open(text_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    formula_so_far = ''\n",
        "    prompt_ds = content\n",
        "\n",
        "    # Setup GPT basic prompt \n",
        "    system_message = formulator(role='user', text=gpt_system_prompt)\n",
        "    messages = [system_message]\n",
        "    messages.append(formulator(role='user', text=natural_language_task))\n",
        "\n",
        "    step_count = 1\n",
        "    help_rate = 0\n",
        "    while True:\n",
        "        print(f\"Currently at step {step_count}\")\n",
        "        user_input = f\"Formula so far: {formula_so_far}\\nStep {step_count}:\"\n",
        "        messages.append(formulator(role='user', text=user_input))\n",
        "        note = os.path.join(foldername, str(f\"step_{step_count}.txt\"))\n",
        "        f = open(note, 'w')\n",
        "        my = CustomOutput(f)\n",
        "        my.write(f\"\\nTask:\\nNL instruction: {natural_language_task}\\nFormula_so_far: {formula_so_far}\\nStep: {step_count}\")\n",
        "        prompt_ds += f\"\\nTask:\\nNL instruction: {natural_language_task}\\nFormula so far: {formula_so_far}\\nStep {step_count}:\\nGENERATE ONLY ONE SYMBOL\\n\"\n",
        "        results = {}\n",
        "        # Obtain M LLM responses from the options\n",
        "        responses = []\n",
        "        deepseek_responses = []\n",
        "        for t in range(1,api_per_step+1):\n",
        "            my.write(f\"\\n\\n=============================\\n\")\n",
        "            my.write(f\"API Call {t}/{api_per_step} | Formula so far: {formula_so_far} | GT:{ltlequ}\")\n",
        "            response, response_text = GPT(messages)\n",
        "            valid, found_keys = check_validity(response_text)\n",
        "            responses.append({'is_valid': valid, 'text': response_text, 'found_keys': found_keys})\n",
        "            my.write(f\"\\n-------[ChatGPT][Valid: {valid}]-------\\n\" + f\"LLM Response {t}: \" + response_text.replace('\\n', '') + f\"\\nKeys Found: {found_keys}\")\n",
        "\n",
        "            if valid:\n",
        "                if found_keys[0] not in results:\n",
        "                    results[found_keys[0]] = 0\n",
        "                results[found_keys[0]] += 1\n",
        "\n",
        "        print(f\"\\nThe results vector is {results}\")\n",
        "\n",
        "        if not results:\n",
        "            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!Nothing in the results!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "\n",
        "        # Aggregate similar APs together\n",
        "        keys_to_remove = set()\n",
        "        for key1, key2 in combinations(results.keys(), 2):\n",
        "            if semantic_similarity(key1, key2) > 0.8:\n",
        "                print(f\"High similarity {semantic_similarity(key1, key2)} between {key1} and {key2}\")\n",
        "                results[key1] += results[key2]\n",
        "                keys_to_remove.add(key2)\n",
        "        \n",
        "        for key in keys_to_remove:\n",
        "            del results[key]\n",
        "        \n",
        "        # Compute valid probabilities\n",
        "        total = sum(results.values())\n",
        "        valid_results = {key: value / total for key, value in results.items()}\n",
        "        # my.write(f\"True element is {words[step_count-1]}\\n\")\n",
        "\n",
        "        pred_set = []\n",
        "        for k, v in valid_results.items():\n",
        "            if v >= 1 - alpha: # check the pred set using deepseek first\n",
        "                pred_set.append(k)\n",
        "        \n",
        "        if len(pred_set) != 1:\n",
        "            results_deepseek = {}\n",
        "            deepseek_response = []\n",
        "            for t in range(1, api_per_step+1):\n",
        "                my.write(f\"\\nDeepseek Running in Progress: {t}/{api_per_step}\")\n",
        "                response, response_text = LLM_DS(prompt_ds)\n",
        "                valid, found_keys = check_validity(response_text)\n",
        "                deepseek_response.append({'is_valid': valid, 'text': response_text, 'found_keys': found_keys})\n",
        "                my.write(f\"\\n-------[Deepseek][Valid: {valid}]---------\\n\" + f\"LLM Response {t}: \" + response_text.replace('\\n', '') + f\"\\nKeys Found: {found_keys}\")\n",
        "                if valid:\n",
        "                    if found_keys[0] not in results_deepseek:\n",
        "                        results_deepseek[found_keys[0]] = 0\n",
        "                    results_deepseek[found_keys[0]] += 1\n",
        "                if len(found_keys) == 0:\n",
        "                    continue\n",
        "                print(f\"\\nAdded to {found_keys[0]}\")\n",
        "            print(f\"The results vector is {results_deepseek}\")\n",
        "            total = sum(results_deepseek.values())\n",
        "            valid_results = {key: value / total for key, value in results_deepseek.items()}\n",
        "\n",
        "            for k, v in valid_results.items():\n",
        "                print(f\"{k}: {v}\\n\")\n",
        "            \n",
        "            # List to keep track of keys to remove\n",
        "            keys_to_remove = []\n",
        "            for key1, key2 in combinations(results_deepseek.keys(), 2):\n",
        "                if semantic_similarity(key1, key2) > 0.8:\n",
        "                    print(f\"High similarity {semantic_similarity(key1, key2)} between '{key1}' and '{key2}'\")\n",
        "                    if valid_results[key1] >= valid_results[key2]:\n",
        "                        valid_results[key1] += valid_results[key2]\n",
        "                        keys_to_remove.append(key2)\n",
        "                    else:\n",
        "                        valid_results[key2] += valid_results[key1]\n",
        "                        keys_to_remove.append(key1)\n",
        "\n",
        "            # Remove marked keys from the dictionary\n",
        "            for key in keys_to_remove:\n",
        "                if key in valid_results:\n",
        "                    del valid_results[key]\n",
        "            \n",
        "            pred_set_deepseek = []\n",
        "            for k, v in valid_results.items():\n",
        "                if v >= 1-alpha:\n",
        "                    pred_set_deepseek.append(k)\n",
        "\n",
        "            intersection = list(set(pred_set_deepseek) & set(pred_set))\n",
        "            my.write(f\"\\n===\\nDeepSeek Pred Set: {pred_set_deepseek}\\nGPT Pred Set: {pred_set}\\nIntersection Prediction Set of DeepSeek and GPT is: {intersection}\\n===\\n\")\n",
        "\n",
        "            if len(intersection) == 1:\n",
        "                # DeepSeek + GPT results in a singleton\n",
        "                pred_set[0] = intersection[0]\n",
        "            else:\n",
        "\n",
        "                if len(intersection) == 0:\n",
        "                    print(f\"The translation has failed\")\n",
        "                    break\n",
        "\n",
        "                # Otherwise, go to ask for help from user \n",
        "                user_input_msg = f\"I  need help!\\nNL: {natural_language_task}\\nGT is: {ltlequ}\\nThe current formula is {formula_so_far}\\nChoose an option of the following:\"\n",
        "                my.write(f\"\\n{user_input_msg}\")\n",
        "                for i, option in enumerate(pred_set):\n",
        "                    my.write(f\"\\n{i+1}: {option}\")\n",
        "                user_input = input(user_input_msg)\n",
        "                user_input = int(user_input)\n",
        "                my.write(f\"\\n\\nUser Selected: {pred_set[int(user_input)-1]}\")\n",
        "                pred_set[0] = pred_set[int(user_input)-1]\n",
        "                help_rate += 1\n",
        "        if len(pred_set) == 0:\n",
        "            print(f\"Translation has failed!\")\n",
        "            break\n",
        "        \n",
        "        formula_so_far += pred_set[0]\n",
        "\n",
        "        prompt_ds += f\"{pred_set[0]}\\n\"\n",
        "        messages.append(formulator(role='assistant', text=pred_set[0]))\n",
        "        step_count += 1\n",
        "        my.write(f\"\\nNew Formula: {formula_so_far}\\n\")\n",
        "\n",
        "        if formula_so_far[-1] == '/':\n",
        "            my.write(f\"The current formula is now ended with /, exiting...\")\n",
        "            break\n",
        "    print(f\"\\n{natural_language_task}\")\n",
        "    print(f\"The helps asked: {help_rate} and step count : {step_count-1}\")\n",
        "    correct = True\n",
        "    if ltlequ != formula_so_far:\n",
        "        useranswer = input(f\"Formula so far:{formula_so_far}\\nEnter 'no' if you think it is wrong: \")\n",
        "        if useranswer == 'no':\n",
        "            correct = False \n",
        "    print(f\"The final formula is {'correct' if correct else 'wrong'}\")\n",
        "    json_filename = 'result.json'\n",
        "    if os.path.isfile(json_filename):\n",
        "        with open(json_filename, 'r') as f:\n",
        "            jsondata = json.load(f)\n",
        "    else:\n",
        "        jsondata = []\n",
        "    new_dict = {\n",
        "        \"nlTask\": natural_language_task,\n",
        "        \"ltlequ\": ltlequ,\n",
        "        \"api_per_step\": api_per_step,\n",
        "        'help': help_rate,\n",
        "        \"correct\": correct,\n",
        "        'total_step': step_count -1\n",
        "    }\n",
        "    jsondata.append(new_dict)\n",
        "    with open(json_filename, 'w') as f:\n",
        "      json.dump(jsondata, f, indent=4) # Use indent for pretty printing\n",
        "\n",
        "    print(f\"New data length: {len(jsondata)}\")\n",
        "\n",
        "    # compute help_rate\n",
        "    help = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for data in jsondata:\n",
        "        help = help + data['help']\n",
        "        total = total + data['total_step']\n",
        "        if data['correct']:\n",
        "            correct = correct + 1\n",
        "    print(f\"\\n\\n\\nHelp Rate: {help/total}\\nAccuracy: {correct/len(jsondata)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mrlBBS1V1_az",
        "_zoI1PJvhimC",
        "qQhvXLqrC5rg"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
